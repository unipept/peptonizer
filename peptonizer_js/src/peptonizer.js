import { loadPyodide } from "pyodide";

/**
 * Start the peptonizer. This function takes in a PSM-file that has been read in earlier (so no file paths here). The
 * PSMS including their intensities are then used as input to the Peptonizer-pipeline. This pipeline will finally
 * return a Map in which NCBI taxon IDs are mapped onto their propabilities (as computed by the Peptonizer).
 *
 * @param psmContent Content of a PSM-file generated by upstream tools (such as MS2Rescore).
 * @return Mapping between NCBI taxon IDs (integer, > 0) and probabilities (float in [0, 1]).
 */
export async function peptonize(psmContent) {
    let pyodide = await loadPyodide({indexURL: "https://cdn.jsdelivr.net/pyodide/v0.26.1/full"});

    pyodide.globals.set('input', psmContent);
    // Load all packages into the Pyodide runtime environment that are required by the Peptonizer
    await pyodide.loadPackage(
        [
            'numpy',
            'scipy',
            'networkx',
            'pandas',
            'micropip',
            'requests',
            'openssl'
        ]);

    const data = await (await fetch("data/rescored.psms.tsv")).text();
    pyodide.globals.set('input', data);

    const peptonizerOutput = await pyodide.runPythonAsync(`
        import micropip
        import json
        from sys import getsizeof

        await micropip.install("lib/peptonizer-0.1-py3-none-any.whl")

        import peptonizer

        # The PSM input should be provided to the parser as a list of strings
        psms = [globals().get('input')]

        print("Started parsing pout file from MS2Rescore...")
        parsed_input = peptonizer.parse_ms2rescore_output(psms, 0.01)
        print(f"Input has been parsed successfully... --> size: {getsizeof(parsed_input)}")

        print("Started fetching Unipept taxon information...")
        unipept_responses = peptonizer.fetch_unipept_taxon_information(
            parsed_input,
            "2",
            "species",
            "file_unipept_taxon_information_log"
        )
        print("Successfully fetched Unipept taxon information...")

        print("Started weighing taxa...")
        df, weights = peptonizer.perform_taxa_weighing(
            unipept_responses,
            parsed_input,
            10,
            "species"
        )
        df.to_csv("file_weights_dataframe")
        print("Successfully weighed taxa...")

        print("Start creation of PepGM graph...")
        peptonizer.generate_pepgm_graph(
            "file_weights_dataframe",
            "file_pepgm_graph"
        )
        print("Successfully created PepGM graph...")
        
        def sizeof_fmt(num, suffix='B'):
            for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:
                if abs(num) < 1024.0:
                    return "%3.1f %s%s" % (num, unit, suffix)
                num /= 1024.0
            return "%.1f %s%s" % (num, 'Yi', suffix)
        
        for name, size in sorted(((name, getsizeof(value)) for name, value in list(
                                  locals().items())), key= lambda x: -x[1])[:10]:
            print("{:>30}: {:>8}".format(name, sizeof_fmt(size)))

        print("Started running PepGM...")
        graph_contents = open("file_pepgm_graph", "r").read()
        pepgm_results = peptonizer.run_belief_propagation(
            graph_contents,
            0.9,
            0.6,
            0.5,
            10000,
            25
        )
        print("Successfully executed PepGM...")

        # Now convert the results from PepGM into a list of taxon IDs and the corresponding score values.
        final_scores = peptonizer.extract_taxon_scores(pepgm_results)

        json.dumps(final_scores)
    `);

    console.log("Final output from the PeptonizerJS: ")
    console.log(peptonizerOutput);

    return null;
}

